{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26065a47-6c6d-417e-a9be-57886539ec97",
   "metadata": {},
   "source": [
    "## 算法稳定性检测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "440ca2b6-a227-4edd-b152-5e9a84a50a4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'min_x': 3417664.5,\n",
       " 'max_x': 4080080.0,\n",
       " 'min_y': 4722390.0,\n",
       " 'max_y': 5445893.5,\n",
       " 'min_ts': 0,\n",
       " 'max_ts': 50,\n",
       " 'sampled_tr_path': 'data/geolife-train-ps-80',\n",
       " 'complete_tr_path': 'data/geolife-train-ps-100',\n",
       " 'num_x_grids': 200,\n",
       " 'num_y_grids': 200,\n",
       " 'ts_gap': 1,\n",
       " 'sampled_tr_len': 40,\n",
       " 'complete_tr_len': 50,\n",
       " 'ts_rep_dict_path': 'data/ts_rep_dict.pkl',\n",
       " 'sp_rep_dict_path': 'data/sp_rep_dict.pkl',\n",
       " 'ts_pretrain_model_path': 'data/ts_pretrain_model.pt',\n",
       " 'sp_pretrain_model_path': 'data/sp_pretrain_model.pt',\n",
       " 'sm_pretrain_model_path': 'data/semantic2vec.model',\n",
       " 'bare_dataset_path': 'data/bare_dataset.pt',\n",
       " 'dataset_path': 'data/dataset.pt',\n",
       " 'at2vec_model_path': 'data/at2vec_model.pt',\n",
       " 'at2vec_rep_path': 'data/at2vec_rep_path.pt',\n",
       " 'sp_len': 100,\n",
       " 'ts_len': 100,\n",
       " 'sm_len': 100,\n",
       " 'pt_len': 300,\n",
       " 'hidden_len': 256,\n",
       " 'k': 10,\n",
       " 'batch_size': 8,\n",
       " 'device': device(type='cuda'),\n",
       " 'alpha': 1,\n",
       " 'beta': 1,\n",
       " 'gamma': 1,\n",
       " 'num_ts_grids': 51,\n",
       " 'x_gap': 3312.0775,\n",
       " 'y_gap': 3617.5175,\n",
       " 'num_sp_grids': 40200,\n",
       " 'test_tr_path': 'data/brinkhoff-stability',\n",
       " 'keywords_path': 'data/amap-labels.txt',\n",
       " 'logging_path': 'data/at2vec.log',\n",
       " 'test_batch_size': 1024}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import import_ipynb\n",
    "from at2vec import ctx, sp2id\n",
    "import logging\n",
    "from datetime import datetime\n",
    "# 配置\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    # 训练集参数\n",
    "    ctx.min_x = 3417664.5\n",
    "    ctx.max_x = 4080080.0\n",
    "    ctx.min_y = 4722390.0\n",
    "    ctx.max_y = 5445893.5\n",
    "    ctx.min_ts = 0\n",
    "    ctx.max_ts = 50\n",
    "    \n",
    "    ctx.num_ts_grids = (ctx.max_ts - ctx.min_ts) // ctx.ts_gap + 1\n",
    "    ctx.x_gap, ctx.y_gap = ((ctx.max_x - ctx.min_x) / ctx.num_x_grids,\n",
    "                            (ctx.max_y - ctx.min_y) / ctx.num_y_grids)\n",
    "    ctx.num_sp_grids = sp2id(ctx.max_x, ctx.max_y,\n",
    "                             ctx.min_x, ctx.min_y,\n",
    "                             ctx.max_x, ctx.max_y,\n",
    "                             ctx.x_gap, ctx.y_gap)\n",
    "    \n",
    "    ctx.test_tr_path = 'data/brinkhoff-stability'\n",
    "    ctx.keywords_path = 'data/amap-labels.txt'\n",
    "    ctx.logging_path = 'data/at2vec.log'\n",
    "    ctx.test_batch_size = 1024\n",
    "    \n",
    "    logging.basicConfig(filename=ctx.logging_path, format='%(message)s', level=logging.INFO)\n",
    "    logging.info(str(datetime.now()))\n",
    "    logging.info('running test.ipynb...')\n",
    "   \n",
    "ctx.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2e2b43d-e45c-43d4-b59f-e8f8a7f8e47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm.notebook import trange\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    torch.set_grad_enabled(False)\n",
    "    \n",
    "    \n",
    "class TestDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, bare_dataset, raw2tr):\n",
    "        self.bare_dataset = bare_dataset\n",
    "        self.vectors = []\n",
    "        for i in trange(len(self.bare_dataset)):\n",
    "            _, raw = self.bare_dataset[i]\n",
    "            self.vectors.append(raw2tr(raw))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.bare_dataset)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Returns:\n",
    "            (index, tr)\n",
    "        \"\"\"\n",
    "        tr = self.vectors[index]\n",
    "        return index, tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57c6d631-e28f-45fd-872d-56811a0d50b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import heapq\n",
    "\n",
    "\n",
    "class Evaluator:\n",
    "    \"\"\"\n",
    "    用于检测单个数据集、单个噪音，并查询前k个结果。\n",
    "    \"\"\"\n",
    "    def __init__(self, model, noise, k):\n",
    "        self.model = model\n",
    "        self.noise = noise\n",
    "        self.k = k\n",
    "        self.chosen_tr = None\n",
    "        self.queue = []  # list[distance, index] 大根堆\n",
    "    \n",
    "    def set_chosen_tr_vec(self, tr_vec):\n",
    "        \"\"\"\n",
    "        设置基准轨迹的向量表示。\n",
    "        \n",
    "        Args:\n",
    "            tr: 基准轨迹的向量最终表示\n",
    "        \"\"\"\n",
    "        self.chosen_tr_vec = tr_vec.to(ctx.device)\n",
    "    \n",
    "    def evaluate(self, index: int, raw, tr):\n",
    "        \"\"\"\n",
    "        先对轨迹加噪音，然后保存并返回离基准轨迹的距离。\n",
    "        \n",
    "        Args:\n",
    "            index: 轨迹编号\n",
    "            raw: pd.DataFrame 轨迹的原始表示\n",
    "            tr: torch.Tensor  轨迹的向量表示\n",
    "        Returns:\n",
    "            添加噪音后的轨迹离基准轨迹的距离\n",
    "        \"\"\"\n",
    "        tr = tr.to(ctx.device)\n",
    "        d = torch.dist(self.model.get_rep_vector(\n",
    "            self.noise.apply(raw, tr).to(ctx.device)), \n",
    "            self.chosen_tr_vec).item()\n",
    "        heapq.heappush(self.queue, (-d, index))\n",
    "        if len(self.queue) > self.k:\n",
    "            heapq.heappop(self.queue)\n",
    "        return d\n",
    "    \n",
    "    def evaluate_batch(self, indexes, raw, tr):\n",
    "        assert len(raw) == tr.shape[0]\n",
    "        # (batch_size, hidden_len)\n",
    "        applied = self.model.get_rep_vector(self.noise.apply_batch(raw, tr))\n",
    "        dists = torch.cdist(applied, self.chosen_tr_vec.unsqueeze(0)).squeeze()\n",
    "        for i in range(dists.shape[0]):\n",
    "            heapq.heappush(self.queue, (-dists[i].item(), indexes[i].item()))\n",
    "            if len(self.queue) > self.k:\n",
    "                heapq.heappop(self.queue)\n",
    "                \n",
    "    def evaluate_batch_applied(self, indexes, applied):\n",
    "        dists = torch.cdist(applied, self.chosen_tr_vec.unsqueeze(0)).squeeze()\n",
    "        for i in range(dists.shape[0]):\n",
    "            pair = (-dists[i].item(), indexes[i].item())\n",
    "            heapq.heappush(self.queue, pair)\n",
    "            if len(self.queue) > self.k:\n",
    "                heapq.heappop(self.queue)\n",
    "    \n",
    "    def get_top_k_indexes(self):\n",
    "        return sorted([(-k, v) for (k, v) in self.queue])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d942fb7-c62e-4986-b83a-a8d8e1781f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoNoise:\n",
    "    def apply(self, raw, tr):\n",
    "        return tr\n",
    "\n",
    "    def apply_batch(self, raw, tr):\n",
    "        return tr\n",
    "    \n",
    "    def __str__(self):\n",
    "        return \"no-noise\"\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"NoNoise()\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bb7e085-25f0-4e33-bf0f-a6eed7ec6290",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import Random\n",
    "\n",
    "class PointSample:\n",
    "    def __init__(self, p: float, rand: Random):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            p: 删掉一个轨迹点的概率\n",
    "            rand: Random对象\n",
    "        \"\"\"\n",
    "        assert 0 < p <= 1\n",
    "        self.probability = p\n",
    "        self.rand = rand\n",
    "        \n",
    "    def apply(self, raw, tr):\n",
    "        tr_len = tr.shape[0]\n",
    "        indexes = sorted(self.rand.sample(range(tr_len), k=round(tr_len * (1 - self.probability))))\n",
    "        return tr[indexes]\n",
    "\n",
    "    def apply_batch(self, raws, trs):\n",
    "        # trs: (batch_size, tr_len, pt_len)\n",
    "        tr_len = trs.shape[1]\n",
    "        indexes = sorted(self.rand.sample(range(tr_len), k=round(tr_len * (1 - self.probability))))\n",
    "        return trs[:, indexes]\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'sample-{self.probability}'\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f'PointSample(p={self.probability})'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4719cd1-85bf-490e-9b35-5b0baee60605",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import Random\n",
    "\n",
    "\n",
    "class PointShift:\n",
    "    def __init__(self, width: int, rand: Random):\n",
    "        self.width = width\n",
    "        self.rand = rand\n",
    "        \n",
    "    def apply(self, raw, tr):\n",
    "        tr_len = tr.shape[0]\n",
    "        width = self.width\n",
    "        indexes = [i for i in range(tr_len)]\n",
    "        for i in range(1, tr_len - 1):\n",
    "            # i下标的点应该移动到to\n",
    "            this_width = min(width, i, tr_len - i - 1)\n",
    "            to = i + self.rand.randrange(2 * this_width + 1) - this_width\n",
    "            if to < i:\n",
    "                temp = indexes[to]\n",
    "                for j in range(to, i):\n",
    "                    indexes[j] = indexes[j + 1]\n",
    "                indexes[i] = temp\n",
    "            elif to > i:\n",
    "                temp = indexes[to]\n",
    "                for j in reversed(range(i + 1, to + 1)):\n",
    "                    indexes[j] = indexes[j - 1]\n",
    "                indexes[i] = temp\n",
    "        return tr[indexes]\n",
    "    \n",
    "    def apply_batch(self, raws, trs):\n",
    "        tr_len = trs.shape[1]\n",
    "        width = self.width\n",
    "        indexes = [i for i in range(tr_len)]\n",
    "        for i in range(1, tr_len - 1):\n",
    "            # i下标的点应该移动到to\n",
    "            this_width = min(width, i, tr_len - i - 1)\n",
    "            to = i + self.rand.randrange(2 * this_width + 1) - this_width\n",
    "            if to < i:\n",
    "                temp = indexes[to]\n",
    "                for j in range(to, i):\n",
    "                    indexes[j] = indexes[j + 1]\n",
    "                indexes[i] = temp\n",
    "            elif to > i:\n",
    "                temp = indexes[to]\n",
    "                for j in reversed(range(i + 1, to + 1)):\n",
    "                    indexes[j] = indexes[j - 1]\n",
    "                indexes[i] = temp\n",
    "        return trs[:, indexes]\n",
    "\n",
    "    def __str__(self):\n",
    "        return (f'shift-{self.width}')\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f'PointShift(width={self.width})'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d625cde-9a22-4287-abfa-ae594a0e1745",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import Random\n",
    "\n",
    "\n",
    "class SemanticsSubstitution:\n",
    "    def __init__(self,\n",
    "                 p: float,\n",
    "                 keyword_set,\n",
    "                 raw_to_tr,\n",
    "                 rand: Random):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            p: 替换语义信息的概率\n",
    "            keyword_set: 可用关键词集合\n",
    "            raw_to_tr: 原始表示转化为向量表示的函数\n",
    "            rand: Random对象\n",
    "        \"\"\"\n",
    "        self.probability = p\n",
    "        self.keyword_set = keyword_set\n",
    "        self.rand = rand\n",
    "        self.raw_to_tr = raw_to_tr\n",
    "    \n",
    "    def apply(self, raw, tr):\n",
    "        tr_len = raw.shape[0]\n",
    "        raw_copy = raw.copy()\n",
    "        for i in range(tr_len):\n",
    "            keywords = raw_copy.iloc[i, 4].split(',')\n",
    "            for j in range(len(keywords)):\n",
    "                if self.rand.random() < self.probability:\n",
    "                    keywords[j] = self.rand.choice(self.keyword_set)\n",
    "            raw_copy.iloc[i, 4] = ','.join(keywords)\n",
    "        return self.raw_to_tr(raw_copy).to(ctx.device)\n",
    "    \n",
    "    def apply_batch(self, raw, tr):\n",
    "        return torch.stack([self.apply(r, t) for (r, t) in zip(raw, tr)], dim=0)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return (f'substitute-{self.probability}')\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return (f'SemanticsSubstitution(p={self.probability})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d69a7812-963e-4095-a74b-7b51c701c40b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total lines: 21225850\n",
      "trajectory count: 424517\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa82c403f67b42c6beb1e19579fbaece",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/424517 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import import_ipynb\n",
    "from gensim.models import Word2Vec\n",
    "from functools import partial\n",
    "from at2vec import get_mat, PretrainModel, BareDataset, TrajectoryDataset, EncoderDecoder\n",
    "import torch\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # 准备模型与数据\n",
    "    sp_model = PretrainModel(ctx.num_sp_grids, ctx.sp_len, torch.device('cpu'))\n",
    "    sp_model.load_state_dict(torch.load(ctx.sp_pretrain_model_path)['model'])\n",
    "    ts_model = PretrainModel(ctx.num_ts_grids, ctx.ts_len, torch.device('cpu'))\n",
    "    ts_model.load_state_dict(torch.load(ctx.ts_pretrain_model_path)['model'])\n",
    "    sm_model = Word2Vec.load(ctx.sm_pretrain_model_path)\n",
    "    \n",
    "    model = EncoderDecoder(ctx.sampled_tr_len, ctx.complete_tr_len, ctx.pt_len, ctx.hidden_len,\n",
    "                           ctx.num_sp_grids, ctx.num_ts_grids, len(sm_model.wv), ctx.device)\n",
    "    state = torch.load(ctx.at2vec_model_path)\n",
    "    model.load_state_dict(state['model'])\n",
    "    \n",
    "    raw2tr = partial(get_mat, sp_model=sp_model, ts_model=ts_model, sm_model=sm_model)\n",
    "    \n",
    "    bare_dataset = BareDataset(None, ctx.test_tr_path, update_ctx=False, ctx=ctx)\n",
    "    print(f'trajectory count: {len(bare_dataset)}')\n",
    "    test_dataset = TestDataset(bare_dataset, raw2tr)\n",
    "    test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=ctx.test_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00583274-e59a-44b1-89fe-1925bba6d230",
   "metadata": {},
   "outputs": [],
   "source": [
    "from at2vec import get_mat\n",
    "from random import Random\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     noise = NoNoise()\n",
    "#     evaluator = Evaluator(model=model, noise=noise, k=70)\n",
    "#     total = len(bare_dataset)\n",
    "#     _, chosen_tr = test_dataset[34]\n",
    "#     evaluator.set_chosen_tr_vec(model.get_rep_vector(chosen_tr.to(ctx.device)))\n",
    "    # i = 0\n",
    "    # _, raw = bare_dataset[i]\n",
    "    # _, tr = test_dataset[i]\n",
    "    # tr1 = PointSample(p=0.125, rand=Random(251)).apply(raw, tr)\n",
    "    # tr2 = PointShift(4, Random(251)).apply(raw, tr)\n",
    "    # print(tr, tr1, tr2, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb4efdb-b92b-4af5-a452-861c1b9ff2ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b09abfb25be4ca38f7139deb69d8cd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/415 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b8239b5f6f34e5d863d39b52efe9743",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import math\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    ratios = [0.0 for _ in noises]\n",
    "    \n",
    "    num_queries = 50\n",
    "    \n",
    "    logging.info(f'{num_queries} {len(noises)}')\n",
    "    for noise in noises:\n",
    "        logging.info(f'{noise}')\n",
    "        \n",
    "    tr_count = len(test_dataset)\n",
    "    test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=ctx.test_batch_size)\n",
    "    \n",
    "    evaluators = [[Evaluator(model=model, noise=noise, k=50) for noise in noises] for _ in range(num_queries)]\n",
    "    \n",
    "    for query_id in range(num_queries):\n",
    "        evaluators_per_query = evaluators[query_id]\n",
    "        i = random.randrange(tr_count)\n",
    "        _, chosen_tr = test_dataset[i]        \n",
    "        chosen_tr_vec = model.get_rep_vector(chosen_tr.to(ctx.device))\n",
    "        for evaluator in evaluators_per_query:\n",
    "            evaluator.set_chosen_tr_vec(chosen_tr_vec)\n",
    "            \n",
    "    pbar = tqdm(total=math.ceil(tr_count / ctx.test_batch_size))\n",
    "    pbar1 = tqdm(total=len(noises))\n",
    "    for i, (indexes, trs) in enumerate(test_dataloader):\n",
    "        pbar1.reset()\n",
    "        trs = trs.to(ctx.device)\n",
    "        raws = []\n",
    "        for index in indexes:\n",
    "            # if index.item() % 10 == 0:\n",
    "            #     print(f'processing trajectory #{index.item()}')\n",
    "            index = index.item()\n",
    "            raws.append(test_dataset.bare_dataset[index][1])\n",
    "        \n",
    "        for n, noise in enumerate(noises):\n",
    "            # print(f'batch {i}/{len(test_dataloader)}, noise {noise}')\n",
    "            applied = model.get_rep_vector(noise.apply_batch(raws, trs))\n",
    "            for evaluators_per_query in evaluators:\n",
    "                evaluators_per_query[n].evaluate_batch_applied(indexes, applied)\n",
    "            pbar1.update(1)\n",
    "        pbar.update(1)\n",
    "    pbar.close()\n",
    "    pbar1.close()\n",
    "\n",
    "    for query_id in range(num_queries):\n",
    "        logging.info(f'Query #{query_id}:')\n",
    "        evaluators_per_query = evaluators[query_id]\n",
    "        true_results = evaluators_per_query[0].get_top_k_indexes()\n",
    "        true_tids = [int(tid) for (_, tid) in true_results]\n",
    "        intersect_cnt = []\n",
    "        for evaluator in evaluators_per_query:\n",
    "            logging.info(f'{evaluator.noise}')\n",
    "            results = evaluator.get_top_k_indexes()\n",
    "            tids = [int(tid) for (_, tid) in results]\n",
    "            scores = \" \".join([f'{score:.4f}' for (score, _) in results])\n",
    "            logging.info(\" \".join([str(tid) for tid in tids]))\n",
    "            logging.info(scores)\n",
    "            intersect_cnt.append(count_intersect(tids, true_tids) / len(tids))\n",
    "        logging.info(f\"intersect: {' '.join([f'{cnt:.4f}' for cnt in intersect_cnt])}\")\n",
    "        for i in range(len(ratios)):\n",
    "            ratios[i] += intersect_cnt[i]\n",
    "    \n",
    "    for i in range(len(noises)):\n",
    "        logging.info(f'{noises[i]} {ratios[i] / num_queries}')\n",
    "        print(f'{noises[i]} {ratios[i] / num_queries}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f6c979-9fc8-457d-af6d-fb79da5924e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
