{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8256862b-3974-4163-8258-edb168104fbe",
   "metadata": {},
   "source": [
    "# 计算轨迹相似度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5cac234-8cca-49cd-aae0-faa55fed168e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Configs\n",
    "directory = 'tdrive-data/'\n",
    "training_set_file = directory + 'tdrive-r-train-ps-40'\n",
    "sp_pretrain_model_path = directory + 'sp_pretrain_model.pt'\n",
    "ts_pretrain_model_path = directory + 'ts_pretrain_model.pt'\n",
    "sm_pretrain_model_path = directory + 'semantic2vec.model'\n",
    "at2vec_model_path = directory + 'at2vec_model.pt'\n",
    "trajectory_file = directory + 'tdrive-chosen-fill-with-ts'\n",
    "\n",
    "ts_gap = 10 * 60 * 1000\n",
    "num_x_grids = 200\n",
    "num_y_grids = 200\n",
    "sp_len, ts_len, sm_len = 100, 100, 100\n",
    "pt_len = sp_len + ts_len + sm_len\n",
    "hidden_len = 256\n",
    "sampled_tr_len, complete_tr_len = 40, 50\n",
    "\n",
    "device = torch.device('cpu')\n",
    "\n",
    "INT_MAX = 214748364700000000000\n",
    "FLOAT_MAX = 1E8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ea3b61d-cb63-4d58-b528-5868f2b5584d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts_range (1201930247000, 1202463545000)\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "# These params are needed for loading the model\n",
    "num_sp_grids = None\n",
    "num_ts_grids = None\n",
    "\n",
    "# Recover range info from training set\n",
    "ts_range = (INT_MAX, -INT_MAX)\n",
    "x_range = (FLOAT_MAX, -FLOAT_MAX)\n",
    "y_range = (FLOAT_MAX, -FLOAT_MAX)\n",
    "\n",
    "with open(training_set_file) as f:\n",
    "    for line in f:\n",
    "        fields = line.strip().split('\\t')\n",
    "        ts = int(fields[1])\n",
    "        x = float(fields[2])\n",
    "        y = float(fields[3])\n",
    "        ts_range = min(ts_range[0], ts), max(ts_range[1], ts)\n",
    "        x_range = min(x_range[0], x), max(x_range[1], x)\n",
    "        y_range = min(y_range[0], y), max(y_range[1], y)\n",
    "        \n",
    "\n",
    "def pair2spid(x_id: int, y_id: int, num_x_grids: int):\n",
    "    return y_id * num_x_grids + x_id\n",
    "\n",
    "def sp2id(x: float, y: float,\n",
    "          min_x: float, min_y: float,\n",
    "          max_x: float, max_y: float,\n",
    "          x_gap: float, y_gap: float):\n",
    "    \"\"\"\n",
    "    (x, y)坐标转换为空间网格令牌值。假设max_x和max_y不能取到。\n",
    "\n",
    "    Returns:\n",
    "        令牌值, (x轴编号, y轴编号)\n",
    "    \"\"\"\n",
    "    x, y = max(min_x, x), max(min_y, y)\n",
    "    x, y = min(max_x, x), min(max_y, y)\n",
    "    num_x_grids = int(math.ceil((max_x - min_x) / x_gap))\n",
    "    x_grid, y_grid = (int(math.floor((x - min_x) / x_gap)),\n",
    "                      int(math.floor((y - min_y) / y_gap)))\n",
    "    return pair2spid(x_grid, y_grid, num_x_grids)\n",
    "\n",
    "print('ts_range', ts_range)\n",
    "num_ts_grids = (ts_range[1] - ts_range[0]) // ts_gap + 1\n",
    "x_gap = (x_range[1] - x_range[0]) / num_x_grids\n",
    "y_gap = (y_range[1] - y_range[0]) / num_y_grids\n",
    "num_sp_grids = sp2id(x_range[1], y_range[1],\n",
    "                     x_range[0], y_range[0],\n",
    "                     x_range[1], y_range[1],\n",
    "                     x_gap, y_gap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb601379-a16e-4abe-bb5a-e53f3ab77998",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from at2vec import PretrainModel, EncoderDecoder, BareDataset, get_mat\n",
    "import torch\n",
    "from gensim.models import Word2Vec\n",
    "from functools import partial\n",
    "\n",
    "# load the model\n",
    "sp_model = PretrainModel(num_sp_grids, sp_len, device)\n",
    "sp_model.load_state_dict(torch.load(sp_pretrain_model_path)['model'])\n",
    "ts_model = PretrainModel(num_ts_grids, ts_len, device)\n",
    "ts_model.load_state_dict(torch.load(ts_pretrain_model_path)['model'])\n",
    "sm_model = Word2Vec.load(sm_pretrain_model_path)\n",
    "\n",
    "model = EncoderDecoder(sampled_tr_len, complete_tr_len, pt_len, hidden_len,\n",
    "                       num_sp_grids, num_ts_grids, len(sm_model.wv), device)\n",
    "state = torch.load(at2vec_model_path)\n",
    "model.load_state_dict(state['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb6b27d5-9790-4e19-a170-05408d1cb093",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total lines: 294\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "class TestDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, bare_dataset, raw2tr):\n",
    "        self.bare_dataset = bare_dataset\n",
    "        self.vectors = []\n",
    "        for i in range(len(self.bare_dataset)):\n",
    "            _, raw = self.bare_dataset[i]\n",
    "            self.vectors.append(raw2tr(raw))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.bare_dataset)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Returns:\n",
    "            (index, tr)\n",
    "        \"\"\"\n",
    "        tr = self.vectors[index]\n",
    "        return index, tr\n",
    "\n",
    "\n",
    "def ts2id(ts: int, min_ts: int, max_ts: int, ts_gap: int):\n",
    "    ts = min(max_ts, ts)\n",
    "    ts = max(min_ts, ts)\n",
    "    return int((ts - min_ts) // ts_gap)\n",
    "\n",
    "\n",
    "def get_mat(tr, sp_model, ts_model, sm_model):\n",
    "    get_spid = partial(sp2id, min_x=x_range[0], max_x=x_range[1], min_y=y_range[0], max_y=y_range[1],\n",
    "                       x_gap=x_gap, y_gap=y_gap)\n",
    "    get_tsid = partial(\n",
    "        ts2id, min_ts=ts_range[0],  max_ts=ts_range[1], ts_gap=ts_gap)\n",
    "    ts_col, all_cols, sm_col = (tr.iloc[:, 1],\n",
    "                                tr.iloc[:, 2:4],\n",
    "                                tr.iloc[:, 4])\n",
    "    sp_vec = torch.stack([sp_model.embed(get_spid(al.iloc[0], al.iloc[1]))\n",
    "                          for (_, al) in all_cols.iterrows()], dim=0)\n",
    "    ts_vec = torch.stack([ts_model.embed(get_tsid(ts))\n",
    "                         for (_, ts) in ts_col.iteritems()], dim=0)\n",
    "    # semantics are more complicated\n",
    "    vec_set = []\n",
    "    for _, sm in sm_col.iteritems():\n",
    "        # For each trajectory point\n",
    "        # keyword list of this point\n",
    "        kws = sm.replace(' ', '-').split(',')\n",
    "        # 所有关键词向量取平均并归一化，作为该点语义向量\n",
    "        avg_vec = torch.from_numpy(sm_model.wv.get_mean_vector(\n",
    "            kws, pre_normalize=True, post_normalize=True))\n",
    "        vec_set.append(avg_vec)\n",
    "    sm_vec = torch.stack(vec_set, dim=0)\n",
    "    # returns: (tr_len, sp_len)\n",
    "    return torch.cat((sp_vec, ts_vec, sm_vec), dim=1)\n",
    "\n",
    "\n",
    "raw2tr = partial(get_mat, sp_model=sp_model,\n",
    "                 ts_model=ts_model, sm_model=sm_model)\n",
    "\n",
    "bare_dataset = BareDataset(None, trajectory_file, update_ctx=False, ctx=None)\n",
    "print(len(bare_dataset))\n",
    "dataset = TestDataset(bare_dataset, raw2tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68e7b735-9111-417f-a49a-5a236e77310c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.)\n",
      "tensor(10.3989)\n",
      "tensor(9.4192)\n",
      "tensor(10.5366)\n",
      "tensor(9.8658)\n",
      "tensor(10.2114)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "query_vec = model.get_rep_vector(dataset[0][1])\n",
    "\n",
    "for _, t in dataset:\n",
    "    vec = model.get_rep_vector(t)\n",
    "    dist = torch.dist(query_vec, vec)\n",
    "    print(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b63f399-9b72-40ca-9cc5-d69c5bfdee14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
