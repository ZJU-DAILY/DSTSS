{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "665e43f1-d75d-475f-a77c-b7046d7364ca",
   "metadata": {},
   "source": [
    "## 配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfccb450-113c-4c59-bc47-907863ad711d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "\n",
    "class Context:\n",
    "    \"\"\"配置项\"\"\"\n",
    "    def __init__(self):\n",
    "        self.min_x = None\n",
    "        self.max_x = None\n",
    "        self.min_y = None\n",
    "        self.max_y = None\n",
    "        self.min_ts = None\n",
    "        self.max_ts = None\n",
    "    \n",
    "ctx = Context()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eaa38e2b-324e-4794-b65a-f27ef40bb0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_ctx(self: Context):\n",
    "    # 数据文件夹\n",
    "    data_dir = 'tdrive-data'\n",
    "\n",
    "    def get_dir(path: str):\n",
    "        return os.path.join(data_dir, path)\n",
    "\n",
    "    # 数据文件\n",
    "    self.sampled_tr_path = get_dir('tdrive-r-train-ps-40')\n",
    "    self.complete_tr_path = get_dir('tdrive-r-train-ps-50')\n",
    "    # self.test_sampled_tr_path = get_dir('brinkhoff-stability-head')\n",
    "    # self.test_complete_tr_path = get_dir('geolife-r-train-ps-50')\n",
    "\n",
    "    # 数据特征\n",
    "    self.num_x_grids = 200\n",
    "    self.num_y_grids = 200\n",
    "    self.ts_gap = 10 * 60 * 1000  # 10分钟  # don't forget to change this\n",
    "    # self.ts_gap = 1\n",
    "    self.sampled_tr_len = 40\n",
    "    self.complete_tr_len = 50\n",
    "\n",
    "    # 时空数据表示矩阵\n",
    "    self.ts_rep_dict_path = get_dir('ts_rep_dict.pkl')\n",
    "    self.sp_rep_dict_path = get_dir('sp_rep_dict.pkl')\n",
    "\n",
    "    # 模型文件\n",
    "    self.ts_pretrain_model_path = get_dir('ts_pretrain_model.pt')\n",
    "    self.sp_pretrain_model_path = get_dir('sp_pretrain_model.pt')\n",
    "    self.sm_pretrain_model_path = get_dir('semantic2vec.model')\n",
    "    self.bare_dataset_path = get_dir('bare_dataset.pt')\n",
    "    self.dataset_path = get_dir('dataset.pt')\n",
    "    self.at2vec_model_path = get_dir('at2vec_model.pt')\n",
    "    self.at2vec_rep_path = get_dir('at2vec_rep_path.pt')\n",
    "\n",
    "    # 其他配置\n",
    "    self.sp_len = 100  # 空间表示向量长度\n",
    "    self.ts_len = 100  # 时间表示向量长度\n",
    "    self.sm_len = 100  # 语义表示向量长度\n",
    "    self.pt_len = self.sp_len + self.ts_len + self.sm_len  # 轨迹点表示向量长度\n",
    "    self.hidden_len = 256  # 最终生成的轨迹点向量长度\n",
    "    self.k = 10  # KNN个数\n",
    "    self.batch_size = 32\n",
    "    self.device = torch.device('cuda')\n",
    "    \n",
    "    self.alpha = 1\n",
    "    self.beta = 1\n",
    "    self.gamma = 1\n",
    "\n",
    "\n",
    "init_ctx(ctx)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "afe3553a-a92c-4d2b-ae2c-4e8643bc6239",
   "metadata": {},
   "source": [
    "## 轨迹数据读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4703062c-13b1-4d58-a891-52c1e3b229b9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def cover_none(f, x, y):\n",
    "    # x and y may be None\n",
    "    if x is None and y is None:\n",
    "        return None\n",
    "    if x is None:\n",
    "        return y\n",
    "    if y is None:\n",
    "        return x\n",
    "    return f(x, y)\n",
    "\n",
    "\n",
    "# 读取轨迹文件\n",
    "class BareDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, sampled_tr_path=\"\", complete_tr_path=\"\", ntrs=None, update_ctx=True, *, ctx=None):\n",
    "        if not (sampled_tr_path or complete_tr_path):\n",
    "            sampled_tr_path = ctx.sampled_tr_path\n",
    "            complete_tr_path = ctx.complete_tr_path\n",
    "\n",
    "        def read_data(path: str, nrows: int):\n",
    "            if not path:\n",
    "                return None, None\n",
    "            data = pd.read_csv(path, sep=\"\\t\", nrows=nrows,\n",
    "                               usecols=[0, 1, 2, 3, 4], header=None)\n",
    "            idx = dict()  # tid -> [start_index, len]\n",
    "            current_tid = -1\n",
    "            print('total lines: ' + str(data.shape[0]))\n",
    "            # 假设每条轨迹在文件中是连续的\n",
    "            for i, point in tqdm(data.iterrows(), total=data.shape[0], disable=True):\n",
    "                tid, ts, x, y, semantics = (point.iloc[i] for i in range(5))\n",
    "                if current_tid != tid:\n",
    "                    idx[tid] = [i, 0]\n",
    "                    current_tid = tid\n",
    "                idx[tid][1] += 1\n",
    "                if update_ctx:\n",
    "                    ctx.min_x = cover_none(min, x, ctx.min_x)\n",
    "                    ctx.max_x = cover_none(max, x, ctx.max_x)\n",
    "                    ctx.min_y = cover_none(min, y, ctx.min_y)\n",
    "                    ctx.max_y = cover_none(max, y, ctx.max_y)\n",
    "                    ctx.min_ts = cover_none(min, ts, ctx.min_ts)\n",
    "                    ctx.max_ts = cover_none(max, ts, ctx.max_ts)\n",
    "            return data, idx\n",
    "\n",
    "        nrows = None if ntrs is None else ntrs * ctx.sampled_tr_len\n",
    "        # 读取采样轨迹数据\n",
    "        self.sampled_data, self.sampled_data_idx = read_data(sampled_tr_path, nrows=nrows)\n",
    "\n",
    "        nrows = None if ntrs is None else ntrs * ctx.complete_tr_len\n",
    "        # 读取原始轨迹数据\n",
    "        self.complete_data, self.complete_data_idx = read_data(complete_tr_path, nrows=nrows)\n",
    "\n",
    "        if self.sampled_data_idx is not None and self.complete_data_idx is not None:\n",
    "            assert len(self.sampled_data_idx) == len(self.complete_data_idx)\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.complete_data_idx is not None:\n",
    "            return len(self.complete_data_idx)\n",
    "        return len(self.sampled_data_idx)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if index < 0 or index >= len(self):\n",
    "            raise IndexError\n",
    "            \n",
    "        def get_from(data, data_idx, index):\n",
    "            if data is None:\n",
    "                return None\n",
    "            start_idx, length = data_idx[index]\n",
    "            return data.iloc[start_idx:start_idx+length]\n",
    "\n",
    "        return (get_from(self.sampled_data, self.sampled_data_idx, index),\n",
    "                get_from(self.complete_data, self.complete_data_idx, index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8df28a4-3bda-4ef9-86f2-3a4d1c671660",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total lines: 2000000\n",
      "total lines: 2500000\n",
      "dataset len: 50000\n",
      "{'min_x': 116.15005, 'max_x': 116.59997, 'min_y': 39.75, 'max_y': 40.09967, 'min_ts': 1201930247000, 'max_ts': 1202463545000, 'sampled_tr_path': 'tdrive-data/tdrive-r-train-ps-40', 'complete_tr_path': 'tdrive-data/tdrive-r-train-ps-50', 'test_complete_tr_path': 'tdrive-data/geolife-r-train-ps-50', 'num_x_grids': 200, 'num_y_grids': 200, 'ts_gap': 600000, 'sampled_tr_len': 40, 'complete_tr_len': 50, 'ts_rep_dict_path': 'tdrive-data/ts_rep_dict.pkl', 'sp_rep_dict_path': 'tdrive-data/sp_rep_dict.pkl', 'ts_pretrain_model_path': 'tdrive-data/ts_pretrain_model.pt', 'sp_pretrain_model_path': 'tdrive-data/sp_pretrain_model.pt', 'sm_pretrain_model_path': 'tdrive-data/semantic2vec.model', 'bare_dataset_path': 'tdrive-data/bare_dataset.pt', 'dataset_path': 'tdrive-data/dataset.pt', 'at2vec_model_path': 'tdrive-data/at2vec_model.pt', 'at2vec_rep_path': 'tdrive-data/at2vec_rep_path.pt', 'sp_len': 100, 'ts_len': 100, 'sm_len': 100, 'pt_len': 300, 'hidden_len': 256, 'k': 10, 'batch_size': 32, 'device': device(type='cuda'), 'alpha': 1, 'beta': 1, 'gamma': 1}\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    bare_dataset = BareDataset(ctx.sampled_tr_path, ctx.complete_tr_path, ctx=ctx)\n",
    "    print(f'dataset len: {len(bare_dataset)}')\n",
    "    # torch.save(bare_dataset, ctx.bare_dataset_path)\n",
    "    print(ctx.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ebd8200-ff68-4c95-9653-1de0fa666dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def visualize_data(data: pd.DataFrame, length):\n",
    "    \"\"\"绘制图像\"\"\"\n",
    "    x = data.iloc[:, 2]\n",
    "    y = data.iloc[:, 3]\n",
    "    ts = data.iloc[:, 1]\n",
    "    labels = [x for x in range(len(ts))]\n",
    "    size = len(data)\n",
    "    i = 0\n",
    "    with tqdm(total=size, disable=True) as pbar:\n",
    "        while i < size:\n",
    "            plt.plot(x.iloc[i:i+length-1], y.iloc[i:i+length-1],\n",
    "                     x.iloc[i+1:i+length], y.iloc[i+1:i+length])\n",
    "            i += length\n",
    "            pbar.update(length)\n",
    "    # plt.figure()\n",
    "    # plt.scatter(ts, labels)\n",
    "\n",
    "# visualize_data(bare_dataset.complete_data, ctx.complete_tr_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c84f27fe-1424-410f-9443-ee27db059466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For geolife\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6dae4eeb-ce0b-4216-a555-28c3648aa1dc",
   "metadata": {},
   "source": [
    "## 时空语义信息预处理"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1563d48e-966b-4cd9-a781-4c28ea91f160",
   "metadata": {},
   "source": [
    "### 处理时间标记"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3cab96b-f1b3-48ed-92fa-b734d7b12914",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class PretrainModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, device):\n",
    "        \"\"\"\n",
    "        Args: \n",
    "          vocab_size: 总的单元个数\n",
    "          embed_size: 时间表示向量长度\n",
    "        \"\"\"\n",
    "        super(PretrainModel, self).__init__()\n",
    "\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed_size = embed_size\n",
    "        self.device = device\n",
    "\n",
    "        # Skip-gram参考：https://youtu.be/c2qIe74NN6A?t=3152\n",
    "        self.ctx_embed = nn.Embedding(\n",
    "            self.vocab_size, self.embed_size, max_norm=1)\n",
    "        nn.init.xavier_normal_(self.ctx_embed.weight)\n",
    "        self.tgt_embed = nn.Linear(self.embed_size, self.vocab_size)\n",
    "        nn.init.xavier_normal_(self.tgt_embed.weight)\n",
    "        self.log_softmax = nn.LogSoftmax(dim=1)\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, context: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          context:  中心词 (batch_size), 0 <= value < vocab_size\n",
    "          targets: 上下文词 (batch_size, k), 0 <= value < vocab_size\n",
    "\n",
    "        len: 时间/空间向量维度\n",
    "        k: K近邻个数\n",
    "\n",
    "        Returns: 损失值\n",
    "        \"\"\"\n",
    "        batch_size = context.shape[0]\n",
    "        # vector: (batch_size, embed_size)\n",
    "        vector = self.ctx_embed(context).to(self.device)\n",
    "        # print(f'vector: {vector.shape}, {vector.dtype}')\n",
    "\n",
    "        # Z: (batch_size, vocab_size)\n",
    "        Z = self.tgt_embed(vector).to(self.device)\n",
    "        # print(f'Z: {Z.shape}, {Z.dtype}')\n",
    "\n",
    "        # Y_hat: (batch_size, vocab_size)\n",
    "        Y_hat = self.log_softmax(Z).to(self.device)\n",
    "        # print(f'Y_hat: {Y_hat.shape}, {Y_hat.dtype}')\n",
    "\n",
    "        return self.criterion(Y_hat, targets)\n",
    "\n",
    "    def criterion(self, output, labels):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            output: (batch_size, vocab_size)\n",
    "            labels: (batch_size, k)\n",
    "        Returns: loss\n",
    "        \"\"\"\n",
    "        k = labels.shape[1]\n",
    "        # loss: (batch_size, )\n",
    "        loss = torch.stack([self.loss_fn(output, label)\n",
    "                           for label in torch.unbind(labels, dim=1)])\n",
    "        return loss\n",
    "\n",
    "    def embed(self, index):\n",
    "        with torch.no_grad():\n",
    "            if isinstance(index, int):\n",
    "                index = torch.tensor(index).to(self.device)\n",
    "            return self.ctx_embed(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e8205b6-0fa6-4671-ac0c-3993969ed4bb",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 6, 3, 7]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ts2id(ts: int, min_ts: int, max_ts: int, ts_gap: int):\n",
    "    ts = min(max_ts, ts)\n",
    "    ts = max(min_ts, ts)\n",
    "    return (ts - min_ts) // ts_gap\n",
    "\n",
    "\n",
    "def ts_k_nearest(k: int, max_tsid: int):\n",
    "    \"\"\"返回一个生成K近邻的函数。\"\"\"\n",
    "    def f(tsid: int) -> 'list[int]':\n",
    "        # tsid in [0, max_tsid)\n",
    "        nearest = list()\n",
    "        l = tsid - 1\n",
    "        r = tsid + 1\n",
    "        while True:\n",
    "            if len(nearest) >= k:\n",
    "                break\n",
    "            if l >= 0:\n",
    "                nearest.append(l)\n",
    "                l -= 1\n",
    "            if len(nearest) >= k:\n",
    "                break\n",
    "            if r < max_tsid:\n",
    "                nearest.append(r)\n",
    "                r += 1\n",
    "            if l < 0 and r >= max_tsid:\n",
    "                break\n",
    "        return nearest\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "ts_k_nearest(4, 10)(5)  # [4, 6, 3, 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c57a760-66e1-42a9-b4ab-885da73e060b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader for timestamps data\n",
    "class SpaceTimestampDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, vocab_size, k_nearest, device):\n",
    "        self.vocab_size = vocab_size\n",
    "        self.k_nearest = k_nearest\n",
    "        self.device = device\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.vocab_size\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (torch.tensor(index).to(self.device),\n",
    "                torch.tensor(self.k_nearest(index)).to(self.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5913771d-0fe8-426b-a70b-ccfbc866851d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from d2l import torch as d2l\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import random\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "def validate(model: PretrainModel, k_nearest, num_tests=2) -> float:\n",
    "    \"\"\"验证训练出来的表示向量是否能够反映邻近关系\"\"\"\n",
    "    with torch.no_grad():\n",
    "        count = 0.0\n",
    "        vocab_size = model.vocab_size\n",
    "        for _ in trange(num_tests):\n",
    "            index = random.randrange(vocab_size)\n",
    "            neighbors = k_nearest(index)\n",
    "            id_dist = []\n",
    "            index_vec = model.embed(index)\n",
    "            for j in range(vocab_size):\n",
    "                j_vec = model.embed(j)\n",
    "                id_dist.append((torch.dist(index_vec, j_vec).item(), j))\n",
    "            id_dist.sort()\n",
    "            # print(id_dist[:20])\n",
    "            assert id_dist[0][1] == index\n",
    "            for k in range(1, min(vocab_size, 2 * len(neighbors) + 1)):\n",
    "                if id_dist[k][1] in neighbors:\n",
    "                    count += 1 / len(neighbors)\n",
    "        return count / num_tests\n",
    "\n",
    "\n",
    "def pretrain(dataloader: DataLoader, num_epochs: int, lr: float, vocab_size: int, embed_size: int,\n",
    "             k_nearest, ctx: Context, /, state=None, draw=True, save_path=None):\n",
    "    model = PretrainModel(vocab_size=vocab_size,\n",
    "                          embed_size=embed_size,\n",
    "                          device=ctx.device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    if state is None:\n",
    "        model.to(ctx.device)\n",
    "        start_epoch = 0\n",
    "    else:\n",
    "        model.load_state_dict(state['model'])\n",
    "        model.to(ctx.device)\n",
    "        # optimizer.load_state_dict(state['optimizer'])\n",
    "        start_epoch = state['epoch']\n",
    "\n",
    "    if draw:\n",
    "        board = d2l.ProgressBoard(xlabel=\"epoch\",\n",
    "                                  ylabel=\"loss\",\n",
    "                                  xlim=[start_epoch, start_epoch + num_epochs],\n",
    "                                  figsize=(5, 3))\n",
    "\n",
    "    # xlim=[0, num_epochs])\n",
    "    num_rounds = len(dataloader)\n",
    "    # pbar = tqdm(total=num_epochs)\n",
    "    # pbar1 = tqdm(total=num_rounds)\n",
    "    for epoch in range(start_epoch, start_epoch + num_epochs):\n",
    "        # pbar1.reset()\n",
    "        if not draw:\n",
    "            print(f\"========= Epoch {epoch} ========\")\n",
    "\n",
    "        total_loss = 0\n",
    "        numel = 0\n",
    "        for i, (context, target) in enumerate(dataloader):\n",
    "            optimizer.zero_grad()\n",
    "            loss = model(context, target)\n",
    "            loss_sum = loss.sum()\n",
    "            loss_sum.backward()\n",
    "            optimizer.step()\n",
    "            with torch.no_grad():\n",
    "                total_loss += loss_sum.item()\n",
    "                numel += loss.shape[0]\n",
    "                #if not draw:\n",
    "                #    print(\n",
    "                #        f\"epoch {i+1:4d}/{num_rounds:4d}: loss = {loss_sum / loss.shape[0]:.4f}\")\n",
    "            # pbar1.update(1)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            if draw:\n",
    "                board.draw(epoch, total_loss / numel,\n",
    "                           'loss', every_n=num_epochs // 100)\n",
    "            else:\n",
    "                print(f\"total loss: {total_loss / numel:.4f}\\n\")\n",
    "\n",
    "            if (epoch + 1) % 5 == 0 or epoch + 1 == num_epochs:\n",
    "                # 每100次计算一次accuracy\n",
    "                # val_count = validate(model, k_nearest)\n",
    "                # print(f'accuracy: {val_count}')\n",
    "                # if draw:\n",
    "                #     board.draw(epoch, val_count, 'accuracy')\n",
    "                # 第一次不需要保存\n",
    "                state = {'epoch': epoch + 1,\n",
    "                         'model': model.state_dict(),\n",
    "                         'optimizer': optimizer.state_dict()}\n",
    "                torch.save(state, save_path)\n",
    "                if not draw: print('saved')\n",
    "        # pbar.update(1)\n",
    "    # pbar.close()\n",
    "    # pbar1.close()\n",
    "\n",
    "    print(f'final loss: {total_loss / numel}')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1aa6ea00-cd45-4e2c-a6ba-5d23671cfe98",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # 每个时间切片的长度（单位：ms)\n",
    "    # ctx.ts_gap = 600000\n",
    "    ctx.num_ts_grids = (ctx.max_ts - ctx.min_ts) // ctx.ts_gap + 1"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ebb82261-8de3-4103-8bc2-5e0b7931f250",
   "metadata": {
    "tags": []
   },
   "source": [
    "if __name__ == '__main__':\n",
    "    ts_dataset = SpaceTimestampDataset(ctx.num_ts_grids,\n",
    "                                       ts_k_nearest(ctx.k, ctx.num_ts_grids),\n",
    "                                       ctx.device)\n",
    "    ts_dataloader = torch.utils.data.DataLoader(\n",
    "        ts_dataset, ctx.batch_size * 8, ctx.device)\n",
    "\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    # state = torch.load(ctx.ts_pretrain_model_path)\n",
    "\n",
    "    # model saved in ts_pretrain_model_path\n",
    "    model = pretrain(ts_dataloader, 50, 0.001, ctx.num_ts_grids, ctx.ts_len,\n",
    "                     ts_k_nearest(ctx.k, ctx.num_ts_grids), ctx, draw=False, save_path=ctx.ts_pretrain_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab2fb9b9-da5c-4ec1-b93c-ebae960ae289",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if __name__ == '__main__':\n",
    "#     ts_model = PretrainModel(vocab_size=ctx.num_ts_grids,\n",
    "#                                   embed_size=ctx.ts_len,\n",
    "#                                   device=ctx.device)\n",
    "#     ts_model.load_state_dict(torch.load(ctx.ts_pretrain_model_path)['model'])\n",
    "#     ts_model.to(ctx.device)\n",
    "#     ts_model.embed(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "58054446-254a-44a9-9664-fd2ef2e8081c",
   "metadata": {},
   "source": [
    "### 处理空间标记"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e9bff95-b5c2-4b6d-8799-7515e1a910b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "def pair2spid(x_id: int, y_id: int, num_x_grids: int):\n",
    "    return y_id * num_x_grids + x_id\n",
    "\n",
    "\n",
    "def spid2pair(id: int, num_x_grids: int):\n",
    "    return id % num_x_grids, id // num_x_grids\n",
    "\n",
    "\n",
    "def sp2id(x: float, y: float,\n",
    "          min_x: float, min_y: float,\n",
    "          max_x: float, max_y: float,\n",
    "          x_gap: float, y_gap: float):\n",
    "    \"\"\"\n",
    "    (x, y)坐标转换为空间网格令牌值。假设max_x和max_y不能取到。\n",
    "\n",
    "    Returns:\n",
    "        令牌值, (x轴编号, y轴编号)\n",
    "    \"\"\"\n",
    "    x, y = max(min_x, x), max(min_y, y)\n",
    "    x, y = min(max_x, x), min(max_y, y)\n",
    "    num_x_grids = int(math.ceil((max_x - min_x) / x_gap))\n",
    "    x_grid, y_grid = (int(math.floor((x - min_x) / x_gap)),\n",
    "                      int(math.floor((y - min_y) / y_gap)))\n",
    "    return pair2spid(x_grid, y_grid, num_x_grids)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    spid = sp2id(6, 4.5, 0, 0, 16, 9, 4, 3)\n",
    "    pair = spid2pair(spid, 4)\n",
    "    spid, pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "abed07aa-19ac-4d75-9dae-ac1419b14c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sp_k_nearest(k: int, max_x_id: int, max_y_id: int):\n",
    "    \"\"\"返回一个生成K近邻的函数。\"\"\"\n",
    "    assert 0 < k < max_x_id * max_y_id\n",
    "\n",
    "    def iswithin(x_id, y_id):\n",
    "        return 0 <= x_id < max_x_id and 0 <= y_id < max_y_id\n",
    "\n",
    "    def f(spid: int) -> 'list[int]':\n",
    "        # 使用Manhattan距离\n",
    "        # x_id in [0, max_x_id)\n",
    "        # y_id in [0, max_y_id)\n",
    "        x_id, y_id = spid2pair(spid, max_x_id)\n",
    "\n",
    "        nearest = list()\n",
    "        dist = 1\n",
    "        while True:\n",
    "            delta_x_abs = dist - dist // 2\n",
    "            while delta_x_abs <= dist:\n",
    "                delta_x = delta_x_abs\n",
    "                delta_y = dist - delta_x\n",
    "\n",
    "                diagonal = delta_x == delta_y or delta_y == 0\n",
    "\n",
    "                for _ in range(4):\n",
    "                    new_x_id = x_id + delta_x\n",
    "                    new_y_id = y_id + delta_y\n",
    "                    if iswithin(new_x_id, new_y_id):\n",
    "                        nearest.append(pair2spid(new_x_id, new_y_id, max_x_id))\n",
    "                        if len(nearest) >= k:\n",
    "                            return nearest\n",
    "                    if not diagonal:\n",
    "                        new_x_id = x_id + delta_y\n",
    "                        new_y_id = y_id + delta_x\n",
    "                        if iswithin(new_x_id, new_y_id):\n",
    "                            nearest.append(\n",
    "                                pair2spid(new_x_id, new_y_id, max_x_id))\n",
    "                            if len(nearest) >= k:\n",
    "                                return nearest\n",
    "                    delta_x, delta_y = -delta_y, delta_x  # 顺时针旋转90°\n",
    "\n",
    "                delta_x_abs += 1\n",
    "            dist += 1\n",
    "\n",
    "    return f\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    sp_k_nearest(20, 7, 7)(24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "882322d0-afe5-49ed-9aa7-d396e90dda15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # 每个时间切片的长度（单位：ms)\n",
    "    ctx.x_gap, ctx.y_gap = ((ctx.max_x - ctx.min_x) / ctx.num_x_grids,\n",
    "                            (ctx.max_y - ctx.min_y) / ctx.num_y_grids)\n",
    "    ctx.num_sp_grids = sp2id(ctx.max_x, ctx.max_y,\n",
    "                             ctx.min_x, ctx.min_y,\n",
    "                             ctx.max_x, ctx.max_y,\n",
    "                             ctx.x_gap, ctx.y_gap)\n",
    "    ctx.num_sp_grids"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5fbe8dc8-3c2e-48c3-b3c9-3ed72b3f66c4",
   "metadata": {
    "tags": []
   },
   "source": [
    "if __name__ == '__main__':\n",
    "    sp_dataset = SpaceTimestampDataset(ctx.num_sp_grids,\n",
    "                                       sp_k_nearest(\n",
    "                                           ctx.k, ctx.num_x_grids, ctx.num_y_grids),\n",
    "                                       ctx.device)\n",
    "    sp_dataloader = torch.utils.data.DataLoader(\n",
    "        sp_dataset, ctx.batch_size * 8, ctx.device)\n",
    "\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    # state = torch.load(ctx.sp_pretrain_model_path)\n",
    "\n",
    "    # model saved in sp_pretrain_model_path\n",
    "    model = pretrain(sp_dataloader, 50, 0.001, ctx.num_sp_grids, ctx.sp_len,\n",
    "                     sp_k_nearest(ctx.k, ctx.num_x_grids, ctx.num_y_grids), ctx,\n",
    "                     save_path=ctx.sp_pretrain_model_path, draw=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a9935988-ea70-43b2-a0c0-cd0ad747964b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == '__main__':\n",
    "#     sp_model = PretrainModel(vocab_size=ctx.num_sp_grids,\n",
    "#                                   embed_size=ctx.sp_len,\n",
    "#                                   device=ctx.device)\n",
    "#     sp_model.load_state_dict(torch.load(ctx.sp_pretrain_model_path)['model'])\n",
    "#     sp_model.to(ctx.device)\n",
    "#     sp_model.embed(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "29bc9654-80b9-4a63-9c69-7deda78213de",
   "metadata": {},
   "source": [
    "### 处理语义标记"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f0c991eb-c030-4a43-9081-d52cc6c80be1",
   "metadata": {},
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    sentences = []\n",
    "    for _, tr in bare_dataset:\n",
    "        for _, pt in tr.iterrows():\n",
    "            semantics = pt.iloc[4].replace(' ', '-').split(',')\n",
    "            sentences.append(semantics)\n",
    "    print(sentences[:50])\n",
    "\n",
    "    word2vec = Word2Vec(sentences=sentences, vector_size=100, window=5, min_count=1, workers=28, epochs=10)\n",
    "    word2vec.save(ctx.sm_pretrain_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c4073a04-25cf-4159-ba8a-ff30b9ca1c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from gensim.models import Word2Vec\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     word2vec = Word2Vec.load(ctx.sm_pretrain_model_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8300feea-5a41-411f-a667-d15dadcefe5d",
   "metadata": {},
   "source": [
    "### 轨迹特征融合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3aa746a5-2cfc-41b2-85b6-3a5a1f90aaa7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from gensim.models import Word2Vec\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "def get_mat(tr, sp_model, ts_model, sm_model):\n",
    "    get_spid = partial(sp2id, min_x=ctx.min_x, max_x=ctx.max_x, min_y=ctx.min_y, max_y=ctx.max_y,\n",
    "                           x_gap=ctx.x_gap, y_gap=ctx.y_gap)\n",
    "    get_tsid = partial(ts2id, min_ts=ctx.min_ts,\n",
    "                           max_ts=ctx.max_ts, ts_gap=ctx.ts_gap)\n",
    "    ts_col, all_cols, sm_col = (tr.iloc[:, 1],\n",
    "                                tr.iloc[:, 2:4],\n",
    "                                tr.iloc[:, 4])\n",
    "    sp_vec = torch.stack([sp_model.embed(get_spid(al.iloc[0], al.iloc[1]))\n",
    "                          for (_, al) in all_cols.iterrows()], dim=0)\n",
    "    ts_vec = torch.stack([ts_model.embed(get_tsid(ts))\n",
    "                         for (_, ts) in ts_col.iteritems()], dim=0)\n",
    "    # semantics are more complicated\n",
    "    vec_set = []\n",
    "    for _, sm in sm_col.iteritems():\n",
    "        # For each trajectory point\n",
    "        # keyword list of this point\n",
    "        kws = sm.replace(' ', '-').split(',')\n",
    "        # 所有关键词向量取平均并归一化，作为该点语义向量\n",
    "        avg_vec = torch.from_numpy(sm_model.wv.get_mean_vector(\n",
    "            kws, pre_normalize=True, post_normalize=True))\n",
    "        vec_set.append(avg_vec)\n",
    "    sm_vec = torch.stack(vec_set, dim=0)\n",
    "    # returns: (tr_len, sp_len)\n",
    "    return torch.cat((sp_vec, ts_vec, sm_vec), dim=1)\n",
    "\n",
    "\n",
    "class TrajectoryDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,\n",
    "                 bare_dataset: BareDataset,\n",
    "                 sp_model: PretrainModel,\n",
    "                 ts_model: PretrainModel,\n",
    "                 sm_model: Word2Vec,\n",
    "                 ctx: Context):\n",
    "        self.bare_dataset = bare_dataset\n",
    "        length = len(bare_dataset)\n",
    "        self.length = length\n",
    "        \n",
    "        dev = ctx.device\n",
    "        if self.bare_dataset.sampled_data is not None:\n",
    "            self.sampled_tr = torch.zeros(\n",
    "                length, ctx.sampled_tr_len, ctx.pt_len)\n",
    "            for i in range(length):\n",
    "                if i % 10000 == 0:\n",
    "                    print(f'processing sampled trajectory #{i}')\n",
    "                bare_tr, _ = self.bare_dataset[i]\n",
    "                self.sampled_tr[i, :] = get_mat(bare_tr, sp_model, ts_model, sm_model).cpu()\n",
    "        else:\n",
    "            self.sampled_tr = None\n",
    "\n",
    "        if self.bare_dataset.complete_data is not None:\n",
    "            self.complete_tr = torch.zeros(\n",
    "                length, ctx.complete_tr_len, ctx.pt_len)\n",
    "            for i in range(length):\n",
    "                if i % 10000 == 0:\n",
    "                    print(f'processing full trajectory #{i}')\n",
    "                _, bare_tr = self.bare_dataset[i]\n",
    "                self.complete_tr[i, :] = get_mat(bare_tr, sp_model, ts_model, sm_model).cpu()\n",
    "        else:\n",
    "            self.complete_tr = None\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sampled = self.sampled_tr[index] if self.sampled_tr is not None else None\n",
    "        complete = self.complete_tr[index] if self.complete_tr is not None else None\n",
    "        return index, sampled, complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a914b175-7d35-4941-a884-09d84ae2c3e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 得到轨迹向量表示\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    sp_model = PretrainModel(ctx.num_sp_grids, ctx.sp_len, torch.device('cpu'))\n",
    "    sp_model.load_state_dict(torch.load(ctx.sp_pretrain_model_path)['model'])\n",
    "    ts_model = PretrainModel(ctx.num_ts_grids, ctx.ts_len, torch.device('cpu'))\n",
    "    ts_model.load_state_dict(torch.load(ctx.ts_pretrain_model_path)['model'])\n",
    "    sm_model = Word2Vec.load(ctx.sm_pretrain_model_path)\n",
    "\n",
    "    # dataset = TrajectoryDataset(bare_dataset, sp_model, ts_model, sm_model, ctx)\n",
    "    # torch.save(dataset, ctx.dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "181c497d-b75b-4d5e-8297-0f2d7a08b2f0",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    dataset = torch.load(ctx.dataset_path)\n",
    "    # print(dataset[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e6436448-6d6b-4640-b4a8-0333ffcdd272",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 模型定义\n",
    "\n",
    "### 注意力机制"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "282985a8-6303-4241-bf65-c4abb84ae66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    \"\"\"注意力机制\"\"\"\n",
    "\n",
    "    def __init__(self, hidden_len, vec_len, atten_len):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            hidden_len\n",
    "            vec_len\n",
    "            atten_len\n",
    "\n",
    "        Point-level:   N_e=hidden_len, N=vec_len=atten_len\n",
    "        Feature-level: N_e=hidden_len, T=vec_len=atten_len\n",
    "        Encoder-level: N_d=hidden_len, N_e=vec_len, N_p=atten_len\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.vec_len = vec_len\n",
    "        self.hidden_len = hidden_len\n",
    "        # 对(h_{t-1}, q_{t-1}^e)施加的线性变换\n",
    "        # h是encoder hidden state，q是encoder cell state\n",
    "        self.W1 = nn.Linear(2 * hidden_len, atten_len)\n",
    "        # 对E(·,j)施加的线性变换\n",
    "        # E(·,j)是第j个轨迹点的表示向量\n",
    "        self.W2 = nn.Linear(vec_len, atten_len)\n",
    "        self.v1 = nn.Linear(atten_len, 1)\n",
    "        # 不需要b1，因为Linear层含bias\n",
    "\n",
    "    def forward(self, src, h, q, t):\n",
    "        \"\"\"\n",
    "        Args: （Point|Feature|Encoder attention)\n",
    "            src: 采样轨迹|采样轨迹|encoder hidden state\n",
    "                 (batch_size, sampled_tr_len, pt_len->vec_len)\n",
    "            h: t-1时刻encoder hidden state|encoder hidden state|decoder hidden state\n",
    "            q: t-1时刻encoder cell state|encoder cell state|decoder cell state\n",
    "            t: 当前时刻（即当前是轨迹中的第几个点，从0开始计数）\n",
    "\n",
    "        Returns: (batch_size, atten_len)\n",
    "        \"\"\"\n",
    "        # part_1: (batch_size, atten_len)\n",
    "        part_1 = self.W1(torch.cat((h, q), dim=1))\n",
    "        # part_2: (batch_size, sampled_tr_len, atten_len)\n",
    "        part_2 = self.W2(src)\n",
    "        # a: (batch_size, sampled_tr_len)\n",
    "        a = self.v1(torch.tanh(part_1.unsqueeze(1) + part_2)).squeeze()\n",
    "        if len(a.shape) == 1:\n",
    "            a = a.unsqueeze(0)\n",
    "        a = torch.exp(a)\n",
    "        a = a / torch.pow(a.sum(dim=1, keepdim=True), 1 / (t+1))\n",
    "        return a"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f0f4dacd-fa3e-4407-b2af-e0a1b7f23e1d",
   "metadata": {},
   "source": [
    "### 编码器—解码器模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ad4b43e5-4087-4566-8fce-e675a69b13c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, sampled_tr_len, pt_len, hidden_len, device):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            sampled_tr_len: 采样轨迹长度（轨迹点个数）\n",
    "            pt_len: 轨迹点特征个数（表示向量长度）\n",
    "            hidden_len: 隐藏层大小\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.sampled_tr_len = sampled_tr_len\n",
    "        self.pt_len = pt_len\n",
    "        self.hidden_len = hidden_len\n",
    "        self.device = device\n",
    "\n",
    "        self.lstm_cell = nn.LSTMCell(pt_len, hidden_len)\n",
    "        self.point_attn = Attention(hidden_len, pt_len, pt_len)\n",
    "        self.feature_attn = Attention(\n",
    "            hidden_len, sampled_tr_len, sampled_tr_len)\n",
    "\n",
    "    def forward(self, sampled_tr):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            sampled_tr: 采样轨迹 (batch_size, sampled_tr_len, pt_len)\n",
    "        Returns: \n",
    "            (enc_hiddens, enc_cell)\n",
    "            enc_hiddens: 编码器所有hidden state (batch_size, sampled_tr_len, hidden_len)\n",
    "            enc_cell:    编码器最后时刻cell state (batch_size, hidden_len)\n",
    "        \"\"\"\n",
    "        batch_size = sampled_tr.shape[0]\n",
    "        enc_hiddens = torch.zeros(\n",
    "            (batch_size, self.sampled_tr_len, self.hidden_len)).to(self.device)\n",
    "        enc_hidden = torch.zeros((batch_size, self.hidden_len)).to(self.device)\n",
    "        enc_cell = torch.zeros((batch_size, self.hidden_len)).to(self.device)\n",
    "        for t in range(self.sampled_tr_len):\n",
    "            # point_attn_vec: (batch_size, sampled_tr_len, 1)\n",
    "            point_attn_vec = self.point_attn(\n",
    "                sampled_tr, enc_hidden, enc_cell, t).unsqueeze(2)\n",
    "            # point_attn_matrix: (batch_size, ptr_len, sampled_tr_len)\n",
    "            point_attn_matrix = (sampled_tr * point_attn_vec).transpose(1, 2)\n",
    "            # feature_attn_vec: (batch_size, ptr_len, 1)\n",
    "            feature_attn_vec = self.feature_attn(\n",
    "                point_attn_matrix, enc_hidden, enc_cell, t).unsqueeze(2)\n",
    "            # feature_attn_matrix: (batch_size, sampled_tr_len, pt_len)\n",
    "            feature_attn_matrix = (point_attn_matrix *\n",
    "                                   feature_attn_vec).transpose(1, 2)\n",
    "            # enc_hidden, enc_cell: (batch_size, hidden_len)\n",
    "            enc_hidden, enc_cell = self.lstm_cell(\n",
    "                feature_attn_matrix[:, t], (enc_hidden, enc_cell))\n",
    "            enc_hiddens[:, t] = enc_hidden\n",
    "        return enc_hiddens, enc_cell\n",
    "\n",
    "    def get_rep_vector(self, tr):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            tr: 轨迹 ([batch_size,] *tr_len, pt_len)\n",
    "        Returns: \n",
    "            最终表示 ([batch_size,] hidden_len)\n",
    "        \"\"\"\n",
    "        if len(tr.shape) == 2:\n",
    "            tr = tr.unsqueeze(0)\n",
    "            \n",
    "        batch_size, tr_len, _ = tr.shape\n",
    "        enc_hidden = torch.zeros((batch_size, self.hidden_len)).to(self.device)\n",
    "        enc_cell = torch.zeros((batch_size, self.hidden_len)).to(self.device)\n",
    "        for t in range(tr_len):\n",
    "            # point_attn_vec: (batch_size, tr_len, 1)\n",
    "            point_attn_vec = self.point_attn(\n",
    "                tr, enc_hidden, enc_cell, t).unsqueeze(2)\n",
    "            # point_attn_matrix: (batch_size, tr_len, pt_len)\n",
    "            point_attn_matrix = (tr * point_attn_vec)\n",
    "            # enc_hidden, enc_cell: (batch_size, hidden_len)\n",
    "            enc_hidden, enc_cell = self.lstm_cell(\n",
    "                point_attn_matrix[:, t], (enc_hidden, enc_cell))\n",
    "        return enc_hidden.squeeze()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    encoder = Encoder(3, 4, 5, torch.device('cpu'))\n",
    "    sampled_tr = torch.ones((2, 3, 4))\n",
    "    h, c = encoder(sampled_tr)\n",
    "    h, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b0ec9dc7-67b3-4800-8e7d-28710300b359",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, complete_tr_len, pt_len, hidden_len, device):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            pt_len: 轨迹点特征个数（表示向量长度）\n",
    "            hidden_len: 隐藏层大小\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.complete_tr_len = complete_tr_len\n",
    "        self.pt_len = pt_len\n",
    "        self.hidden_len = hidden_len\n",
    "        self.device = device\n",
    "\n",
    "        self.lstm_cell = nn.LSTMCell(pt_len + hidden_len, hidden_len)\n",
    "        self.enc_attn = Attention(hidden_len, hidden_len, hidden_len)\n",
    "\n",
    "    def forward(self, complete_tr, enc_hiddens, enc_cell):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            complete_tr: 完整轨迹 (batch_size, complete_tr_len, pt_len)\n",
    "            enc_hiddens: 编码器所有隐藏层 (batch_size, sampled_tr_len, hidden_len)\n",
    "            enc_cell:    编码器最后时刻cell state (batch_size, hidden_len)\n",
    "        Returns:\n",
    "            解码器所有隐藏层 (batch_size, complete_tr_len, hidden_len)\n",
    "        \"\"\"\n",
    "        batch_size = complete_tr.shape[0]\n",
    "        # dec_hiddens: (batch_size, complete_tr_len, hidden_len)\n",
    "        dec_hiddens = torch.zeros(\n",
    "            batch_size, self.complete_tr_len, self.hidden_len).to(self.device)\n",
    "        # dec_hidden: (batch_size, hidden_len)\n",
    "        dec_hidden = enc_hiddens[:, -1, :]\n",
    "        # print('initial dec_hidden:', dec_hidden)\n",
    "        # dec_cell\n",
    "        dec_cell = enc_cell\n",
    "\n",
    "        for t in range(self.complete_tr_len):\n",
    "            # enc_attn_vec: (batch_size, 1, sampled_tr_len)\n",
    "            enc_attn_vec = self.enc_attn(\n",
    "                enc_hiddens, dec_hidden, dec_cell, t).unsqueeze(1)\n",
    "            # c_t: (batch_size, hidden_len)\n",
    "            c_t = torch.bmm(enc_attn_vec, enc_hiddens).squeeze()\n",
    "            # pt_and_c_t: (batch_size, pt_size + hidden_len)\n",
    "            pt_and_c_t = torch.cat((complete_tr[:, t], c_t), dim=1)\n",
    "            dec_hidden, dec_cell = self.lstm_cell(\n",
    "                pt_and_c_t, (dec_hidden, dec_cell))\n",
    "        \n",
    "            # print('dec_hidden:', dec_hidden)\n",
    "            dec_hiddens[:, t] = dec_hidden\n",
    "            # TODO: c?\n",
    "\n",
    "        return dec_hiddens\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    decoder = Decoder(6, 4, 5, torch.device('cpu'))\n",
    "    complete_tr = torch.ones(2, 6, 4)\n",
    "    o, _ = decoder(complete_tr, h, c)\n",
    "    o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5a000b7b-8d89-4a11-8fe4-13149dd3207e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderDecoder(nn.Module):\n",
    "    def __init__(self, sampled_tr_len, complete_tr_len, pt_len, hidden_len,\n",
    "                 num_sp_grids, num_ts_grids, num_keywords, device):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            sampled_tr_len: 采样轨迹长度\n",
    "            complete_tr_len: 完整轨迹长度\n",
    "            pt_len: 轨迹点特征数（向量长度）\n",
    "            hidden_len: 隐藏层维度\n",
    "            num_sp_grids: 空间网格个数\n",
    "            num_ts_grids: 时间单位个数\n",
    "            num_keywords: 语义词汇个数\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(sampled_tr_len, pt_len, hidden_len, device)\n",
    "        self.decoder = Decoder(complete_tr_len, pt_len, hidden_len, device)\n",
    "        self.sp_dense = nn.Linear(hidden_len, num_sp_grids)\n",
    "        self.ts_dense = nn.Linear(hidden_len, num_ts_grids)\n",
    "        self.sm_dense = nn.Linear(hidden_len, num_keywords)\n",
    "        self.to(device)\n",
    "\n",
    "    def forward(self, sampled_tr, complete_tr):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            sampled_tr:  采样轨迹 (batch_size, sampled_tr_len,  pt_len)\n",
    "            complete_tr: 完整轨迹 (batch_size, complete_tr_len, pt_len)\n",
    "        Returns: (_, _, _), _\n",
    "            sp_prediction 空间预测 (batch_size, complete_tr_len, num_sp_grids)\n",
    "            ts_prediction 时间预测 (batch_size, complete_tr_len, num_ts_grids)\n",
    "            sm_prediction 语义预测 (batch_size, complete_tr_len, num_keywords)\n",
    "            c             最终表示 (batch_size, hidden_len)\n",
    "        \"\"\"\n",
    "        enc_hiddens, enc_cell = self.encoder(sampled_tr)\n",
    "        dec_hiddens = self.decoder(complete_tr, enc_hiddens, enc_cell)\n",
    "        sp_prediction = self.sp_dense(dec_hiddens)\n",
    "        ts_prediction = self.ts_dense(dec_hiddens)\n",
    "        sm_prediction = self.sm_dense(dec_hiddens)\n",
    "        c = enc_hiddens[:, -1]\n",
    "        return (sp_prediction, ts_prediction, sm_prediction), c\n",
    "    \n",
    "    def get_rep_vector(self, tr):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            tr: 采样轨迹 (batch_size, sampled_tr_len, pt_len)\n",
    "        Returns:\n",
    "            最终表示 (batch_size, hidden_len)\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            return self.encoder.get_rep_vector(tr)\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    enc_dec = EncoderDecoder(3, 6, 4, 5, 10, 20, 30, torch.device('cpu'))\n",
    "    sampled_tr = torch.ones(2, 3, 4)\n",
    "    complete_tr = torch.ones(2, 6, 4)\n",
    "    (p1, p2, p3), c = enc_dec(sampled_tr, complete_tr)\n",
    "    p1.shape, p2.shape, p3.shape, c.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aa9df52b-62f8-45db-b54b-5a9c2793b998",
   "metadata": {},
   "source": [
    "### STA损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "28958e52-de71-40df-93d4-011ba6597277",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def get_sp_knn(ctx: Context, k: int):\n",
    "    \"\"\"\n",
    "    返回一个函数，该函数输入为x、y坐标值，输出为k个邻近的空间网格令牌值。\n",
    "    \"\"\"\n",
    "    knn_func = sp_k_nearest(k, ctx.num_x_grids, ctx.num_y_grids)\n",
    "\n",
    "    def f(x: float, y: float) -> 'list[int]':\n",
    "        spid = sp2id(x, y, ctx.min_x, ctx.min_y, ctx.max_x,\n",
    "                     ctx.max_y, ctx.x_gap, ctx.y_gap)\n",
    "        return [spid] + knn_func(spid)\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "def get_ts_knn(ctx: Context, k: int):\n",
    "    \"\"\"\n",
    "    返回一个函数，该函数输入为时间戳值，输出为k个邻近的时间单元令牌值。\n",
    "    \"\"\"\n",
    "    knn_func = ts_k_nearest(k, ctx.num_ts_grids)\n",
    "\n",
    "    def f(ts: int) -> 'list[int]':\n",
    "        tsid = ts2id(ts, ctx.min_ts, ctx.max_ts, ctx.ts_gap)\n",
    "        return [tsid] + knn_func(tsid)\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "def get_sm_knn(model: Word2Vec, ctx: Context, k: int):\n",
    "    \"\"\"\n",
    "    返回一个函数，该函数输入为某个轨迹点的语义向量（即所有关键词向量的平均），\n",
    "    输出与该语义向量最相邻的k个关键词。\n",
    "    \"\"\"\n",
    "    def f(vec: torch.Tensor) -> 'list[str]':\n",
    "        vec_cpu = vec.cpu()\n",
    "        knn = model.wv.similar_by_vector(vec_cpu.detach().numpy(), topn=k)\n",
    "        return [key for (key, similarity) in knn]\n",
    "\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d4871d04-5edf-47ff-91f4-8f8da89ac5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.cuda import memory_allocated\n",
    "\n",
    "def inspect_memory():\n",
    "    pass\n",
    "    # print(f'memory allocated: {memory_allocated() / 1024 / 1024:.2f} MB')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b0d582e1-2812-4052-98d3-38aa5f714a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "def criterion(sp_prediction: torch.Tensor,\n",
    "              ts_prediction: torch.Tensor,\n",
    "              sm_prediction: torch.Tensor,\n",
    "              true_tr: torch.Tensor,\n",
    "              index: torch.Tensor,\n",
    "              k: int,\n",
    "              alpha: float,\n",
    "              beta: float,\n",
    "              gamma: float,\n",
    "              ts_start: int,\n",
    "              sm_start: int,\n",
    "              pt_len: int,\n",
    "              sp_knn,\n",
    "              ts_knn,\n",
    "              sm_knn,\n",
    "              sp_model: PretrainModel,\n",
    "              ts_model: PretrainModel,\n",
    "              sm_model: Word2Vec,\n",
    "              bare_dataset: BareDataset,\n",
    "              device):\n",
    "    \"\"\"\n",
    "    STA损失函数。\n",
    "\n",
    "    Args:\n",
    "        sp_prediction: 空间预测 (batch_size, complete_tr_len, num_sp_grids)\n",
    "        ts_prediction: 时间预测 (batch_size, complete_tr_len, num_ts_grids)\n",
    "        sm_prediction: 语义预测 (batch_size, complete_tr_len, num_keywords)\n",
    "        true_tr:  完整轨迹 (batch_size, complete_tr_len, pt_len)\n",
    "        index: 轨迹编号 (batch_size, )\n",
    "        k: KNN个数\n",
    "        alpha: 空间部分权重\n",
    "        beta:  时间部分权重\n",
    "        gamma: 语义部分权重\n",
    "        ts_start: 时间信息开始于 (100)\n",
    "        sm_start: 语义信息开始于 (200)\n",
    "        pt_len:  总长度 (300)\n",
    "        sp_knn: 输入x/y，返回空间网格k近邻spid+自身spid\n",
    "        ts_knn: 输入ts，返回时间分段k近邻tsid+自身tsid\n",
    "        sm_knn: 输入语义tensor array (sm_len,)，返回k近邻(list[str])\n",
    "        sp_model: \n",
    "        ts_model:\n",
    "        sm_model:\n",
    "        bare_dataset: BareDataset \n",
    "        device: \n",
    "    Returns:\n",
    "        损失值 (batch_size, )\n",
    "    \"\"\"\n",
    "    inspect_memory()\n",
    "    batch_size, complete_tr_len, _ = sp_prediction.shape\n",
    "    cross_entropy = torch.nn.CrossEntropyLoss(reduction='none')\n",
    "    # loss_pts: list of (batch_size, ), len=complete_tr_len\n",
    "    loss_pts = []\n",
    "    for t in range(complete_tr_len):\n",
    "        inspect_memory()\n",
    "        # 准备第t个轨迹点\n",
    "        # true_pt: (batch_size, 1, pt_len)\n",
    "        true_pt = true_tr[:, t:t+1]\n",
    "        # raw: pd.DataFrame (batch_size, [tid, ts, x, y, kw])\n",
    "        raw = []\n",
    "        for i in range(batch_size):\n",
    "            pt_raw = bare_dataset[index[i].item()][1].iloc[t]\n",
    "            raw.append(pt_raw)\n",
    "\n",
    "        # 空间（此部分K近邻包含自己，k=k+1）\n",
    "        predicted_sp = sp_prediction[:, t].unsqueeze(1)  # (batch_size, 1, num_sp_grids)\n",
    "        true_sp = true_pt[:, :, :ts_start]  # (batch_size, 1, sp_len)\n",
    "        # knn_sp: 目标轨迹点KNN\n",
    "        knn_label_set = []\n",
    "        knn_vec_set = []\n",
    "        for i in range(batch_size):\n",
    "            x, y = raw[i].iloc[2], raw[i].iloc[3]\n",
    "            labels = sp_knn(x, y)  # list of spid\n",
    "            knn_label_set.append(labels)\n",
    "            # knn_vec_i: (k, sp_len)\n",
    "            knn_vec_i = torch.stack([sp_model.embed(spid).to(device) \n",
    "                                     for spid in labels], dim=0)\n",
    "            knn_vec_set.append(knn_vec_i)\n",
    "        # knn_sp_labels: (batch_size, k)\n",
    "        knn_sp_labels = torch.tensor(knn_label_set, device=device)\n",
    "        # knn_sp_vec: (batch_size, k, sp_len)\n",
    "        knn_sp_vec = torch.stack(knn_vec_set, dim=0)\n",
    "        # w_sp: (batch_size, k)\n",
    "        w_sp = -torch.linalg.vector_norm(knn_sp_vec - true_sp, dim=2) / alpha\n",
    "        w_sp = F.softmax(w_sp, dim=1)\n",
    "        # ce_sp: (batch_size, k) -- cross entropy works on axis 1\n",
    "        ce_sp = cross_entropy(predicted_sp.expand(-1, knn_sp_labels.shape[1], -1).permute(0, 2, 1), \n",
    "                              knn_sp_labels)\n",
    "        # loss_sp_pt: (batch_size, )\n",
    "        loss_sp_pt = torch.mean(w_sp * ce_sp, dim=1)\n",
    "        \n",
    "        # 时间（此部分K近邻包含自己，k=k+1）\n",
    "        predicted_ts = ts_prediction[:, t].unsqueeze(1)  # (batch_size, 1, num_ts_grids)\n",
    "        true_ts = true_pt[:, :, :ts_start]  # (batch_size, 1, ts_len)\n",
    "        # knn_ts: 目标轨迹点KNN\n",
    "        knn_label_set = []\n",
    "        knn_vec_set = []\n",
    "        for i in range(batch_size):\n",
    "            ts = raw[i].iloc[1]\n",
    "            labels = ts_knn(ts)  # list of tsid\n",
    "            knn_label_set.append(labels)\n",
    "            # knn_vec_i: (k, ts_len)\n",
    "            knn_vec_i = torch.stack([ts_model.embed(int(tsid)).to(device) \n",
    "                                     for tsid in labels], dim=0)\n",
    "            knn_vec_set.append(knn_vec_i)\n",
    "        # knn_ts_labels: (batch_size, k)\n",
    "        knn_ts_labels = torch.tensor(knn_label_set, device=device)\n",
    "        # knn_ts_vec: (batch_size, k, ts_len)\n",
    "        knn_ts_vec = torch.stack(knn_vec_set, dim=0)\n",
    "        # w_ts: (batch_size, k)\n",
    "        w_ts = -torch.linalg.vector_norm(knn_ts_vec - true_ts, dim=2) / alpha\n",
    "        w_ts = F.softmax(w_ts, dim=1)\n",
    "        # ce_ts: (batch_size, k) -- cross entropy works on axis 1\n",
    "        ce_ts = cross_entropy(predicted_ts.expand(-1, knn_ts_labels.shape[1], -1).permute(0, 2, 1), \n",
    "                              knn_ts_labels) \n",
    "        # loss_ts_pt: (batch_size, )\n",
    "        loss_ts_pt = torch.mean(w_ts * ce_ts, dim=1)\n",
    "        \n",
    "        # 语义\n",
    "        predicted_sm = sm_prediction[:, t].unsqueeze(1)  # (batch_size, 1, num_keywords)\n",
    "        true_sm = true_pt[:, :, :ts_start]  # (batch_size, 1, sm_len)\n",
    "        # knn_sm: 目标轨迹点KNN\n",
    "        knn_label_set = []\n",
    "        knn_vec_set = []\n",
    "        for i in range(batch_size):\n",
    "            # true_sm_vec: (sm_len, )\n",
    "            true_sm_vec = true_sm[i].squeeze()\n",
    "            knn_keywords = sm_knn(true_sm_vec)\n",
    "            labels = [sm_model.wv.get_index(kw) for kw in knn_keywords]\n",
    "            knn_label_set.append(labels)\n",
    "            # knn_vec_i: (k, sm_len)\n",
    "            knn_vec_i = torch.stack([torch.tensor(sm_model.wv.get_vector(kw), device=device)\n",
    "                                     for kw in knn_keywords], dim=0)\n",
    "            knn_vec_set.append(knn_vec_i)\n",
    "        # knn_sm_labels: (batch_size, k)\n",
    "        knn_sm_labels = torch.tensor(knn_label_set, device=device)\n",
    "        # knn_sm_vec: (batch_size, k, sm_len)\n",
    "        knn_sm_vec = torch.stack(knn_vec_set, dim=0)\n",
    "        # w_sm: (batch_size, k)\n",
    "        w_sm = -F.cosine_similarity(knn_sm_vec, true_sm, dim=2) / gamma\n",
    "        w_sm = F.softmax(w_sm, dim=1)\n",
    "        # ce_sm: (batch_size, k) -- cross entropy works on axis 1\n",
    "        ce_sm = cross_entropy(predicted_sm.expand(-1, knn_sm_labels.shape[1], -1).permute(0, 2, 1), \n",
    "                              knn_sm_labels) \n",
    "        # loss_sm_pt: (batch_size, )\n",
    "        loss_sm_pt = torch.sum(w_sm * ce_sm, dim=1)\n",
    "        \n",
    "        loss_pts.append(loss_sp_pt + loss_ts_pt + loss_sm_pt)\n",
    "\n",
    "    return torch.stack(loss_pts, dim=1).sum(dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ddb2974b-b9f6-47a0-a8da-b3b42fd4693b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    _, _, true_tr = dataset[5]\n",
    "    true_tr = true_tr.unsqueeze(0).cuda()\n",
    "    # 轨迹长度：8\n",
    "    sp_prediction = torch.rand(1, 50, ctx.num_sp_grids, dtype=torch.float32).cuda()\n",
    "    ts_prediction = torch.rand(1, 50, ctx.num_ts_grids, dtype=torch.float32).cuda()\n",
    "    sm_prediction = torch.ones(1, 50, len(sm_model.wv), dtype=torch.float32).cuda()\n",
    "\n",
    "    sp_knn_func = get_sp_knn(ctx, ctx.k)\n",
    "    ts_knn_func = get_ts_knn(ctx, ctx.k)\n",
    "    sm_knn_func = get_sm_knn(sm_model, ctx, ctx.k)\n",
    "\n",
    "    criterion(sp_prediction, ts_prediction, sm_prediction, true_tr, torch.Tensor([5]), \n",
    "              ctx.k, 1, 1, 1, 100, 200, 300,\n",
    "              sp_knn_func, ts_knn_func, sm_knn_func,\n",
    "              sp_model, ts_model, sm_model,\n",
    "              bare_dataset, torch.device('cuda'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "418bba82-aba7-432d-a722-6269c17b976f",
   "metadata": {},
   "source": [
    "## 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8653a6b3-22ea-41ba-a9ce-9c2393e20389",
   "metadata": {},
   "outputs": [],
   "source": [
    "from d2l import torch as d2l\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import random\n",
    "from functools import partial\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# def validate(model: PretrainModel, k_nearest, num_tests=100) -> float:\n",
    "#     \"\"\"验证训练出来的表示向量是否能够反映邻近关系\"\"\"\n",
    "#     with torch.no_grad():\n",
    "#         count = 0.0\n",
    "#         vocab_size = model.vocab_size\n",
    "#         for _ in range(num_tests):\n",
    "#             index = random.randrange(vocab_size)\n",
    "#             neighbors = k_nearest(index)\n",
    "#             id_dist = []\n",
    "#             index_vec = model.embed(index)\n",
    "#             for j in range(vocab_size):\n",
    "#                 j_vec = model.embed(j)\n",
    "#                 id_dist.append((torch.dist(index_vec, j_vec).item(), j))\n",
    "#             id_dist.sort()\n",
    "#             # print(id_dist[:20])\n",
    "#             assert id_dist[0][1] == index\n",
    "#             for k in range(1, min(vocab_size, 2 * len(neighbors) + 1)):\n",
    "#                 if id_dist[k][1] in neighbors:\n",
    "#                     count += 1 / len(neighbors)\n",
    "#         return count / num_tests\n",
    "\n",
    "\n",
    "def train(model: EncoderDecoder, dataloader: DataLoader,\n",
    "          sp_model: PretrainModel, ts_model: PretrainModel, sm_model: PretrainModel,\n",
    "          bare_dataset: BareDataset,\n",
    "          num_epochs: int, lr: float, ctx: Context, /, state=None, draw=True,\n",
    "          save_path=None):\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    if state is None:\n",
    "        start_epoch = 0\n",
    "    else:\n",
    "        model.load_state_dict(state['model'])\n",
    "        # optimizer.load_state_dict(state['optimizer'])\n",
    "        start_epoch = state['epoch']\n",
    "\n",
    "    if draw:\n",
    "        board = d2l.ProgressBoard(xlabel=\"epoch\",\n",
    "                                  ylabel=\"loss\",\n",
    "                                  xlim=[start_epoch, start_epoch + num_epochs],\n",
    "                                  figsize=(5, 3))\n",
    "        \n",
    "    sp_knn_func = get_sp_knn(ctx, ctx.k)\n",
    "    ts_knn_func = get_ts_knn(ctx, ctx.k)\n",
    "    sm_knn_func = get_sm_knn(sm_model, ctx, ctx.k)\n",
    "    loss_fn = partial(criterion, k=ctx.k, alpha=ctx.alpha, beta=ctx.beta, gamma=ctx.gamma,\n",
    "                      ts_start=ctx.sp_len, sm_start=ctx.sp_len+ctx.ts_len, pt_len=ctx.pt_len,\n",
    "                      sp_knn=sp_knn_func, ts_knn=ts_knn_func, sm_knn=sm_knn_func,\n",
    "                      sp_model=sp_model, ts_model=ts_model, sm_model=sm_model,\n",
    "                      bare_dataset=bare_dataset, device=ctx.device)\n",
    "                      \n",
    "    # xlim=[0, num_epochs])\n",
    "    num_rounds = len(dataloader)\n",
    "    pbar = tqdm(total=num_epochs * num_rounds)\n",
    "    for epoch in range(num_epochs):\n",
    "        save = True  # 是否保存数据？\n",
    "        \n",
    "        if not draw:\n",
    "            print(f\"========= Epoch {epoch} =========\")\n",
    "\n",
    "        total_loss = 0\n",
    "        numel = 0\n",
    "        for i, (index, sampled, complete) in enumerate(dataloader):\n",
    "            optimizer.zero_grad()\n",
    "            index = index.to(ctx.device)\n",
    "            sampled = sampled.to(ctx.device)\n",
    "            complete = complete.to(ctx.device)\n",
    "            (sp_pred, ts_pred, sm_pred), c = model(sampled, complete)\n",
    "            loss = loss_fn(sp_pred, ts_pred, sm_pred, complete, index)\n",
    "            # print(f'after loss reserved: {torch.cuda.memory_reserved()}')\n",
    "            loss_sum = loss.sum()\n",
    "            loss_sum.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss_sum.item()\n",
    "            numel += loss.shape[0]\n",
    "            if not draw and i % 20 == 0:\n",
    "                print(\n",
    "                    f\"loss = {loss_sum / loss.shape[0]:.4f} [{i+1:4d}/{num_rounds:4d}]\")\n",
    "            pbar.update(1)\n",
    "            \n",
    "        with torch.no_grad():\n",
    "            if draw:\n",
    "                board.draw(epoch, total_loss / numel,\n",
    "                           'loss', every_n=num_epochs // 100)\n",
    "            else:\n",
    "                print(f\"total loss: {total_loss / numel:.4f}\\n\")\n",
    "\n",
    "            if save:\n",
    "                # 每100次计算一次accuracy\n",
    "                # val_count = validate(model, k_nearest)\n",
    "                # print(f'accuracy: {val_count}')\n",
    "                if draw:\n",
    "                    board.draw(epoch, val_count, 'accuracy')\n",
    "\n",
    "                state = {'epoch': epoch + 1,\n",
    "                         'model': model.state_dict(),\n",
    "                         'optimizer': optimizer.state_dict()}\n",
    "                torch.save(state, save_path)\n",
    "    pbar.close()\n",
    "\n",
    "    print(f'final loss: {total_loss / numel}')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8587247d-53f9-484d-8c56-82b3f668db29",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=ctx.batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0577a7-091d-466d-b481-a931ac660f2e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "478069a78c57429383f0d60f263aba4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3126 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Epoch 0 =========\n",
      "loss = 367.1755 [   1/1563]\n",
      "loss = 358.8768 [  21/1563]\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "from datetime import datetime\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    start = datetime.now()\n",
    "    model = EncoderDecoder(ctx.sampled_tr_len, ctx.complete_tr_len, ctx.pt_len, ctx.hidden_len,\n",
    "                          ctx.num_sp_grids, ctx.num_ts_grids, len(sm_model.wv), ctx.device)\n",
    "\n",
    "    # state = torch.load(ctx.at2vec_model_path)\n",
    "\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    state = None\n",
    "    # state = torch.load(ctx.at2vec_model_path)\n",
    "    train(model, dataloader, sp_model, ts_model, sm_model, bare_dataset, 2, 0.001,\n",
    "          ctx, state=state, draw=False, \n",
    "          save_path=ctx.at2vec_model_path)\n",
    "    end = datetime.now()\n",
    "    print(f'training time: {end - start}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2f6503af-69f5-4b2a-91f2-249f2667d413",
   "metadata": {},
   "source": [
    "## 测试准确度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c094d8-3f28-4b8a-b119-1c368b88f06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import heapq\n",
    "\n",
    "def test_accuracy(model: EncoderDecoder, test_dataset, device):\n",
    "    \"\"\"\n",
    "    测试准确度。\n",
    "    \n",
    "    Args:\n",
    "        test_dataloader\n",
    "    \"\"\"\n",
    "    # no grad\n",
    "    K = 50\n",
    "    queue = []  # list[distance, index]\n",
    "\n",
    "    i = random.randrange(len(test_dataset))\n",
    "    chosen_index, _, chosen_tr = test_dataset[i]\n",
    "    chosen_vec = model.get_rep_vector(chosen_tr.to(device))\n",
    "    \n",
    "    dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=128)\n",
    "   \n",
    "    # print(f'chosen: {chosen_index} {chosen_vec.shape}')\n",
    "    for indexes, _, trs in dataloader:\n",
    "        vecs = model.get_rep_vector(trs.to(device))\n",
    "        for i in range(indexes.shape[0]):\n",
    "            heapq.heappush(queue, (-torch.dist(vecs[i], chosen_vec), int(indexes[i])))\n",
    "            if len(queue) > K:\n",
    "                heapq.heappop(queue)\n",
    "    queue.sort(reverse=True)\n",
    "    hit_count = 0\n",
    "    min_accepted_idx = chosen_index // 50 * 50\n",
    "    max_accepted_idx = min_accepted_idx + 49\n",
    "    for _, idx in queue:\n",
    "        print(f\"{idx:7d} \", end=\"\")\n",
    "        if min_accepted_idx <= idx <= max_accepted_idx:\n",
    "            hit_count += 1\n",
    "    print()\n",
    "    for dist, _ in queue:\n",
    "        print(f\"{-dist:.5f} \", end=\"\")\n",
    "    print()\n",
    "    print(f'#{chosen_index}: {hit_count} / 50', end='\\n\\n')\n",
    "    return hit_count / 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c3447a-f339-46d9-b3a2-c312379bba0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    model = EncoderDecoder(ctx.sampled_tr_len, ctx.complete_tr_len, ctx.pt_len, ctx.hidden_len,\n",
    "                           ctx.num_sp_grids, ctx.num_ts_grids, len(sm_model.wv), ctx.device)\n",
    "\n",
    "    state = torch.load(ctx.at2vec_model_path)\n",
    "    model.load_state_dict(state['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561cdf9b-27ac-4fd4-b465-8dc4bd8e706d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    bare_dataset = BareDataset(sampled_tr_path=None,\n",
    "                               complete_tr_path=ctx.test_complete_tr_path,\n",
    "                               update_ctx=False, ctx=ctx)\n",
    "    test_dataset = TrajectoryDataset(bare_dataset, sp_model, ts_model, sm_model, ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33b68dc-b091-4f6e-ad21-f7d4d67612dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    accuracy = 0\n",
    "    test_k = 50\n",
    "    for i in range(test_k):\n",
    "        accuracy += test_accuracy(model, test_dataset, ctx.device)\n",
    "    accuracy / test_k"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
